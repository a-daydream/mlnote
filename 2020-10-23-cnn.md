# Convolutional Neural network

## Why CNN for image?

### CNN vs DNN

我们可以用一般的neural network做图像处理，会遇到问题，**我们直接用一般的fully connected和feedforward network会需要太多的参数**。

![image-20201023204126225](C:\Users\liucheng\AppData\Roaming\Typora\typora-user-images\image-20201023204126225.png)

比如一张100*100的图片，它的vector的size是 100 * 100 * 3,也就是说input vector就是3万维，假设hidden layer有1000个neuron，那么仅仅第一层就有30000 * 1000 个参数。

所以CNN做的事情是**简化neural network的架构，根据我们自己的知识将一些实际上用不到的参数过滤掉，不用fully connected network，而是用比较少的参数实现图像处理**，所以CNN比DNN更加简单。

### Three Property for CNN theory base

怎么过滤参数呢？有一下三个对于图像处理的观察：（**CNN架构提出的基础**）

> Some patterns are much smaller than the whole image

假设第一层hidden layer里，neuron做的事情是探测有没有一种pattern(图片样式，比如小鸟的鸟嘴)，我们知道这样的pattern是比整张图片小的，所以实际上neuron只需要看一张图的小部分，也就是说**每一个neuron要探测的部分更小对应更少的参数**。

![image-20201023205220144](C:\Users\liucheng\AppData\Roaming\Typora\typora-user-images\image-20201023205220144.png)

> The same patterns appear in different regions

同样的pattern可能出现在图片的不同部分，但是它们的形状相同，含义相同，应该是可以用同一个neuron，同样的参数，被同一个detector检测出来

![image-20201023205538134](C:\Users\liucheng\AppData\Roaming\Typora\typora-user-images\image-20201023205538134.png)

我们可以训练一个neuron，detector来做检测同一个pattern的工作，**它们可以共用一组参数，从而减少总参数的数量**。

> Subsampling the pixels will not change the object

我们可以对一张图片进行subsampling(二次抽样)，比如将图片的某些数量的行列拿掉，图片会变小，但是不影响人对图的理解。

![image-20201023210040721](C:\Users\liucheng\AppData\Roaming\Typora\typora-user-images\image-20201023210040721.png)

通过subsampling可以将图片变小，减少参数的数量。

## The whole CNN structure

整个CNN的架构，首先输入一张图片，它会通过Convolution的layer，然后做max pooling(最大池取样)然后重复两个步骤多次(**次数提前设定**)，做完Convolution、Max Pooling后进行Flatten,做完Flatten以后将output丢到fully connected network里面去，最终得到图像处理的结果。

![image-20201023210647952](C:\Users\liucheng\AppData\Roaming\Typora\typora-user-images\image-20201023210647952.png)

我们基于之前提到的对三个图像处理的观察，设计了CNN架构，第一个是探测pattern，只需要探测图片的一个小部分，第二个是同样的pattern会出现在不同的部分,第三个是可以对图片进行subsampling。

对于前二者，用Convolution的layer处理，第三个用max pooling处理。

![image-20201023211132713](C:\Users\liucheng\AppData\Roaming\Typora\typora-user-images\image-20201023211132713.png)

### Convolution

假设有一张6*6的图片作为输入，图片是黑白的，每个pixel中1代表黑色，在Convolution layer里面，有一堆filter,每一个filter实际上等同于fully connected layer里面的一个neuron。

#### property1

![image-20201023211533180](C:\Users\liucheng\AppData\Roaming\Typora\typora-user-images\image-20201023211533180.png) 

每个filter实际上是一个matrix，matrix里面每个element的值是network的参数，是根据训练集训练出来的。上图中每个filter是3*3的size，这代表它在探测一个3 * 3的pattern，**它在探测时候只看图片中3 * 3个pixel的区域**。

#### property2

filter从左上角开始，做slide window，每次向右边移动一定距离(stride),距离大小需要设计，每次filter停下的时候与对应的matrix做内积(相同位置相乘，并且累加求和)，这里假设stride=1，filter每次移动1格，当它碰到图片最右边，就从下一行最左边继续上诉操作，经过整个Convolution的处理，最终得到下图红色的4*4的matrix，观察可以知道，filter的作用就是检测有没有连续的从左上角到右下角的1，1，1，此时filter的卷积结果在左上角和左下角出现最大值，这就代表说filter探测的pattern出现在图片的左上角和右下角。

**我们探测到同一个pattern在图片的左上角和右下角，用了同一个filter，这与property2的考虑一样**。

